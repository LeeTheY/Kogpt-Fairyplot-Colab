# 동화 줄거리 생성 AI 모델 (KoGPT2 Fine-tuning)

사용자 키워드 기반으로 **일관성 있는 동화 줄거리를 자동 생성**하는 AI 언어모델 개발 프로젝트입니다.  
AI-Hub 동화 데이터를 활용해 **한국어 GPT-2 기반 모델(KoGPT2)** 을 파인튜닝하여  
창의적이고 자연스럽게 연결된 스토리 콘텐츠 생성이 최종 목표입니다.

---

## 학습 모델 (KoGPT2)

- SKT에서 공개한 GPT-2 기반 **한국어 특화 언어모델**
- Transformer Self-Attention 구조 기반  
  → 문맥 이해 및 자연스러운 문장 생성 가능
- 동화 줄거리 생성에 적합하도록 파인튜닝  
  → 이야기 구성 능력 및 창의적 콘텐츠 품질 향상

---

## 데이터 수집 및 전처리

- 사용 데이터: AI-Hub **동화 줄거리 생성 데이터셋** (약 1,600개)
- 추출 필드: `character`, `plotSummaryText`
- JSON → JSONL 병합 → 학습 텍스트로 변환
- 최종 약 **8만 문장**의 학습 데이터 구축

전처리 절차:
1) 문장 정제  
2) 프롬프트 기반 입력 형식으로 변환  
3) 학습 친화적 토크나이징 적용

---

## 학습 환경 및 파인튜닝 설정

| 항목 | 설정 |
|---|---|
| Platform | Google Colab |
| GPU | Tesla T4 |
| Model | SKT KoGPT-base-v2 |
| Data | 전처리된 약 80k 문장 |
| 주요 라이브러리 | transformers, torch, nltk, konlpy, sklearn, matplotlib |

### 하이퍼파라미터
| Parameter | Value |
|---|---:|
| epochs | 3 / 6 / 12 |
| batch_size | 4 |
| block_size | 512 |

### 샘플링 파라미터
| Parameter | Value | 목적 |
|---|---:|---|
| temperature | 0.8 | 자연스러움 향상 |
| top_k | 40 | 생성 다양성 확보 |
| top_p | 0.9 | 무의미한 단어 억제 |
| repetition_penalty | 1.2 | 단어 반복 방지 |

---

## 모델 평가 및 결과

### 정성적 평가
- 평가 기준: **일관성, 창의성, 자연스러움**
- 사람 직접 평가 수행

### 정량적 평가
- 자동 평가 지표: **BLEU, METEOR, CIDEr**
- Matplotlib 기반 시각화

---

## 평가 1 : Epoch별 성능 비교

- 등장요소 5개 기준
- 요소별 5회씩 생성 → **다양성 + 일관성 평가**

#### Epoch별 특성

| Epoch | 성능 특성 |
|---|---|
| **3** | 문맥 일관성 부족 / 행동 묘사 부자연스러움 / 불필요 문장 등장 |
| **6** | 이야기 흐름 논리적 / 자연스러움↑ / 창의성 일부 향상 |
| **12** | 문장 연결 매우 자연스럽고 실제 동화에 가까운 분위기 |


## 평가 2 : 파인튜닝 전후 비교

| 구분 | 파인튜닝 전 | 파인튜닝 후(Epoch 12) |
|---|---|---|
| 내용 반영 | 등장요소 반영 부족 | 인물·감정·상황 설정 자연스럽게 반영 |
| 문장 구조 | 단순 나열식 | 문맥 흐름 부드럽고 동화다운 구성이며 몰입감↑ |
| 전반 평가 | 의미 전달 어려움 | 품질 전반 향상 |

## 정량적 결과 시각화

| 내용 | 사진 |
|---|---|
| Epoch별 평가 그래프 | <img width="600" alt="Image" src="https://github.com/user-attachments/assets/e4a7c8ac-2ca8-4fc3-a0ff-abf0cd0a73a1" />|
| 파인튜닝 전후 비교 그래프 | <img width="600" alt="Image" src="https://github.com/user-attachments/assets/0e4473ac-32f7-4188-bc9c-72b4767fe69c" /> |

---

## 결론

- **파인튜닝 효과 확실**
- 정량 평가: **Epoch 6** 최고 성능
- 정성 평가: **Epoch 12**가 가장 자연스러운 결과
- 문맥 연결, 창의성, 자연스러움 모두 개선

---

## 한계점 & 개선 방향

### 한계점
- 데이터 다양성 부족 → 특정 패턴 반복
- **과적합** 일부 관찰
- 서사 구조 조정 필요

### 개선 방향
- **데이터 고도화**
  - 더 다양한 이야기 데이터 확보
  - 발단-전개-위기-절정-결말의 서사 구조 반영
- **모델 업그레이드**
  - KoGPT2 → **GPT-4 기반 모델 확장**
  - 창의성과 완결성 강화
